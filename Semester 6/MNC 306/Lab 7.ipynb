{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with missing values and categorical data\n",
    "data = {\n",
    "    'age' : [25, 30, 35, np.nan, 40],\n",
    "    'income' : [50000, 60000, 80000, 70000, 90000],\n",
    "    'city' : ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing values in 'age' with the median\n",
    "df['age'].fillna(df['age'].median(), inplace = True)\n",
    "\n",
    "# Create a new feature: Income per age\n",
    "df['income_per_age'] = df['income'] / df['age']\n",
    "\n",
    "# One-hot encode the 'city' column\n",
    "df_encoded = pd.get_dummies(df, columns = ['city'])\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"FeatureEngineering\").getOrCreate()\n",
    "\n",
    "# Create a Spark DataFrame\n",
    "data = [\n",
    "    (25, 50000, \"New York\"),\n",
    "    (30, 60000, \"Los Angeles\"),\n",
    "    (35, 70000, \"Chicago\"),\n",
    "    (None, 80000, \"Houston\"),\n",
    "    (40, 90000, \"Phoenix\")\n",
    "]\n",
    "\n",
    "columns = [\"age\", \"income\", \"city\"]\n",
    "df_spark = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Impute missing 'age' values (here using an approximate median)\n",
    "median_age = df_spark.approxQuantile(\"age\", [0.5], 0.001)[0]\n",
    "df_spark = df_spark.na.fill({\"age\" : median_age})\n",
    "\n",
    "# Create a new feature: Income per age\n",
    "from pyspark.sql.functions import round\n",
    "df_spark = df_spark.withColumn(\"income_per_age\", round(col(\"income\") / col(\"age\"), 1))\n",
    "\n",
    "# Encode the 'city' column\n",
    "indexer = StringIndexer(inputCol = \"city\", outputCol = \"city_index\")\n",
    "df_spark = indexer.fit(df_spark).transform(df_spark)\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load MNISTdataset (handwritten digits)\n",
    "mnist = fetch_openml(('mnist_784'), version=1, as_frame=False)\n",
    "X = mnist.data[:5000] # Use a subset for faster processing\n",
    "\n",
    "# Apply PCA to reduce dimensions from 784 to 100\n",
    "pca = PCA(n_components = 100)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "# Percentage of variance retained\n",
    "print(\"Explained Variance Ratio:\", np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "\n",
    "# Reconstruct images from reduced PCA components\n",
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "\n",
    "# Display original and reconstructed images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(X[0].reshape(28, 28), cmap ='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "\n",
    "# Reconstructed image using 100 PCA components\n",
    "axes[1].imshow(X_reconstructed[0].reshape(28, 28), cmap ='gray')\n",
    "axes[1].set_title(\"Reduced Image (PCA)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset\n",
    "df = pd.DataFrame({\n",
    "    'age' : [25, 30, 35, 40, 45],\n",
    "    'income' : [50000, 60000, 70000, 80000, 90000],\n",
    "    'expenses' : [20000, 25000, 30000, 35000, 40000]\n",
    "})\n",
    "\n",
    "# Create interaction features\n",
    "df['income_to_age'] = df['income'] / df['age']\n",
    "df['savings'] = df['income'] - df['expenses']\n",
    "df['savings_rate'] = df['savings'] / df['income'] # Savings as a percentage of income\n",
    "\n",
    "3\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with numerical features\n",
    "df = pd.DataFrame({\n",
    "    'income' : [40000, 50000, 60000, 80000, 100000, 12000],\n",
    "    'spending_score' : [60, 70, 80, 30, 20, 10]\n",
    "})\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters = 3, random_state = 42, n_init = 10)\n",
    "df['customer_segment'] = kmeans.fit_predict(df[['income', 'spending_score']])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
